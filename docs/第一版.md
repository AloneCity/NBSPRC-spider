# 国家统计局的统计用区划代码和城乡划分代码爬取---第一版

首先看下[页面分析](https://github.com/dta0502/China-zoning-code-for-statistics-spider/blob/master/docs/%E9%A1%B5%E9%9D%A2%E5%88%86%E6%9E%90.md)。下面我们开始一步步爬取过程。

## 导入库
```python
import requests
from lxml import etree
import csv
```

## 省级信息爬取

```python
url = "http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2016/index.html"
headers={'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'}
```

这里需要注意一下，国家统计局的统计用区划代码和城乡划分代码网页的编码为`gb2312`。一般我都采用下面的代码来获取页面：
```
data = requests.get(url,headers = headers).text
```
但是在碰到这个编码方式时会出现乱码，所以做出如下改变：

```python
response = requests.get(url,headers = headers)
response.apparent_encoding
```

    'GB2312'


```python
response.encoding = response.apparent_encoding
```

```python
data = response.text
```

## 省级页面解析

### 省级名称、URL获取
```python
selector = etree.HTML(data)
provinceList = selector.xpath('//*[@class="provincetr"]')
```

```python
provinceList
```

    [<Element tr at 0x54a4c88>,
     <Element tr at 0x54b4148>,
     <Element tr at 0x54b4188>,
     <Element tr at 0x54b41c8>]

```python
for i in provinceList:
    provinceName = i.xpath('td/a/text()')
    provinceLink = i.xpath('td/a/@href')
```

下面是根据获取到的每个省的链接进行补全，得到真实的URL。


```python
provinceURL = provinceLink
for i in range(len(provinceLink)):
    for j in range(len(provinceLink[i])):
        provinceURL[i][j][0] = url[:-10] + provinceLink[i][j][0]

provinceURL[0:2]
```

    ['http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2016/11.html',
     'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2016/12.html']



### 市级代码、URL获取

```python
cityCode = [] #第二维的数组
cityLink = []
cityName = []
for provURL in provinceURL:
    response = requests.get(provURL,headers = headers)
    response.encoding = response.apparent_encoding
    data = response.text
    selector = etree.HTML(data)
    cityList = selector.xpath('//tr[@class="citytr"]')
    #下面是抓取每一个城市的代码、URL
    Code = [] #第一维的数组：里面存储了一个省下辖的市的信息
    Link = []
    Name = []
    for i in cityList:
        Code.append(i.xpath('td[1]/a/text()'))
        Link.append(i.xpath('td[1]/a/@href'))
        Name.append(i.xpath('td[2]/a/text()'))
    cityCode.append(Code)
    cityLink.append(Link)
    cityName.append(Name)
```


```python
cityCode[3][0:2]
```

    [['140100000000'], ['140200000000']]


```python
cityLink[3][0:2]
```

    [['14/1401.html'], ['14/1402.html']]


```python
cityName[3][0:2]
```

    [['太原市'], ['大同市']]



下面是根据获取到的每个市的链接进行补全，得到真实的URL。

```python
cityLink[0][0][0]
```

    '11/1101.html'


```python
cityURL = cityLink
for i in range(len(cityLink)):
    for j in range(len(cityLink[i])):
        cityURL[i][j][0] = url[:-10] + cityLink[i][j][0]
```

```python
cityURL[3][0:2]
```

    [['http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2016/14/1401.html'],
     ['http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2016/14/1402.html']]


### 区级代码、URL获取
由于之前获得的市级链接是多维列表的形式，为了后面能够很方便的获取页面，下面将这个链接转换成一维列表形式。

```python
cityURL_list = []
for i in range(len(cityURL)):
    for j in range(len(cityURL[i])):
        cityURL_list.append(cityURL[i][j][0])
```

```python
cityURL_list[0:2]
```

    ['http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2016/11/1101.html',
     'http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2016/12/1201.html']


这里计算下市级区域的个数（为了得到区级信息，需要请求344个url）。

```python
len(cityURL_list)
```

    344


#### 多线程
由于这里的网页请求很多，我将采用多线程来加快速度。


```python
from queue import Queue
from threading import Thread
```


```python
qurl = Queue() #队列
thread_num = 10 #进程数
#下面三个全局变量是每个区的代码、URL、名称信息
countyCode = []
countyURL = []
countyName = []
```


```python
def produce_url(url_list):
    for url in url_list:
        qurl.put(url) # 生成URL存入队列，等待其他线程提取
```


```python
def getCounty():
    while not qurl.empty(): # 保证url遍历结束后能退出线程
        url = qurl.get() # 从队列中获取URL
        response = requests.get(url,headers = headers)
        response.encoding = response.apparent_encoding
        data = response.text
        selector = etree.HTML(data)
        countyList = selector.xpath('//tr[@class="countytr"]')
        #下面是爬取每个区的代码、URL
        for i in countyList:
            countyCode.append(i.xpath('td[1]/a/text()'))
            countyURL.append(i.xpath('td[1]/a/@href'))
            countyName.append(i.xpath('td[2]/a/text()'))
```


```python
def run(url_list):
    produce_url(url_list)
    
    ths = []
    for _ in range(thread_num):
        th = Thread(target = getCounty)
        th.start()
        ths.append(th)
    for th in ths:
        th.join()
```


```python
run(cityURL_list)
```

#### 写入csv文件

```python
with open('county_v1.csv','w',newline = '',encoding = 'utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(["countyCode","countyName","countyURL"])
    for i in range(len(countyCode)):
        writer.writerow([countyCode[i],countyName[i],countyURL[i]])
```

后面的街道信息、居委会信息爬取的代码类似，我就不继续写了。

### 问题
上面的第一版代码存在不少问题，具体见[问题分析](https://github.com/dta0502/China-zoning-code-for-statistics-spider/blob/master/docs/%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90.md)。\
处理完这些问题，就可以模块化上述代码，完成整个设计。
